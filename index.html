<!DOCTYPE html>
<html>
<head>
  <title>POET</title>
    <style>
        .hidden {
            display: none;
        }
    </style>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="https://kit.fontawesome.com/f8ddf9854a.js" crossorigin="anonymous"></script>
  <meta charset="utf-8">
  <meta name="description"
        content="A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI">
  <meta name="keywords" content="POET, Reparameterized LLM Training, Orthogonal Equivalence Transformation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> Reparameterized LLM Training via Orthogonal Equivalence Transformation</title>

  <link rel="icon" href="./static/images/poet_icon.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/question_card.js"></script>
  <script src="./data/results/data_setting.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>
  <script src="./visualizer/data/data_public.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/tablesort/5.2.1/tablesort.min.js"></script>

  <!-- Add the new professional table styles here: -->
  <style>
    /* Professional Table Styles */
    .table-container {
      margin: 2em auto;
      max-width: 900px;
      box-shadow: 0 4px 24px rgba(0,0,0,0.08), 0 1.5px 4px rgba(0,0,0,0.04);
      border-radius: 16px;
      overflow: hidden;
      background: #fff;
    }
    /* ... rest of the new CSS ... */
  </style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <img src="static/images/poet_icon.png" style="width:1em;vertical-align: middle" alt="Logo"/> 
            <span class="mmmu" style="vertical-align: middle">POET</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            Re<strong>p</strong>arameterized LLM Training via <br> <strong>O</strong>rthogonal <strong>E</strong>quivalence <strong>T</strong>ransformation
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/zqiu24" style="text-decoration: none; color: inherit;">Zeju Qiu<sup style="color:#ed4b82;">1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://is.mpg.de/" style="text-decoration: none; color: inherit;">Simon Buchholz<sup style="color:#ed4b82;">1</sup></a>,
            </span>
            <span class="author-block">
                <a href="https://timx.me/" style="text-decoration: none; color: inherit;">Tim Z. Xiao<sup style="color:#ed4b82;">1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://is.mpg.de/" style="text-decoration: none; color: inherit;">Maximilian Dax<sup style="color:#ed4b82;">1</sup></a>,
            </span>
            <span class="author-block">
                <a href="https://is.mpg.de/~bs" style="text-decoration: none; color: inherit;">Bernhard Schölkopf<sup style="color:#ed4b82;">1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://wyliu.com/" style="text-decoration: none; color: inherit;">Weiyang Liu<sup style="color:#ed4b82;">1</sup><sup style="color:#007bff;">2</sup></a>
            </span>
            </div>
            <br>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#ed4b82;">1</sup>Max Planck Institute for Intelligent Systems, Tübingen,</span>
            <span class="author-block"><sup style="color:#007bff;">2</sup>The Chinese University of Hong Kong</span>
          </div>
          <br>
          
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <!-- @PAN TODO: change links -->
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/Sphere-AI-Lab/poet.git"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<style>
  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 80%;
  }
  </style>
  <section class="hero teaser">
    <div class="container is-max-desktop">
          <div class="content has-text-centered">
            <img src="static/images/teaser_poet.png" alt="geometric reasoning" width="100%"/>
            <p> POET's three learning phases. Left: illustration; Middle: angle; Right: loss and validation.</p>
          </div>
      </div>
    </div>
  </section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">POET: A New Training Paradigm for Large Language Models</h2>
        <div class="content has-text-justified">
          <p>
            While Large language models (LLMs) are driving the rapid advancement of artificial intelligence, effectively and reliably training these large models remains one of the field's most significant challenges. To address this challenge, we propose POET, a novel re<strong>P</strong>arameterized training algorithm that uses <strong>O</strong>rthogonal <strong>E</strong>quivalence <strong>T</strong>ransformation to optimize neurons. Specifically, POET reparameterizes each neuron with two learnable orthogonal matrices and a fixed random weight matrix. Because of its provable preservation of spectral properties of weight matrices, POET can stably optimize the objective function with improved generalization. We further develop efficient approximations that make POET flexible and scalable for training large-scale neural networks. Extensive experiments validate the effectiveness and scalability of POET in training LLMs.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
<br>
<br>

<!-- BUILDING SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mmmu">Spectral Property of Weight Matrices</h1>
  </div>
</section>

<section class="section">
  <div class="container">
    <!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->
    <section class="section">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Spectral Perperties and Generalization</h2>
            <div class="content has-text-justified">
              <p>
                The <i>de facto</i> way for training LLMs is to directly optimize weight matrices with the Adam optimizer. While conceptually simple, this direct optimization can be computationally intensive (due to the poor scaling with model size) and requires careful hyperparameter tuning to ensure stable convergence. More importantly, its generalization can remain suboptimal even if the training loss is perfectly minimized. To stabilize training and enhance generalization, various weight regularization methods and weight normalization techniques have been proposed. Most of these methods boil down to improving spectral properties of weight matrices (<i>i.e.</i>, singular values) either explicitly or implicitly. Intuitively, the spectral norm of a weight matrix (<i>i.e.</i>, the largest singular value) provides an upper bound on how much a matrix can amplify the input vectors, which connects to the generalization properties. In general, smaller spectral norms (<i>i.e.</i>, better smoothness) are considered to be associated with stronger generalization, which inspires explicit spectrum control. Theoretical results also suggest that weight matrices with bounded spectrum can provably guarantee generalization.
              </p>
            </div>
          </div>
        </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Spectrum-Preserving Weight Update</h2>
            <div class="content has-text-justified">
              <p>
                To achieve effective weight spectrum control without the limitations above, we propose POET, a re<u>P</u>arameterized training algorithm that uses <u>O</u>rthogonal <u>E</u>quivalence <u>T</u>ransformation to indirectly learn weight matrices. Specifically, POET reparameterizes a weight matrix 
                \( \mathbf{W} \in \mathbb{R}^{m \times n} \) 
                with 
                \( \mathbf{R} \mathbf{W}_0 \mathbf{P} \)
                where 
                \( \mathbf{W}_0 \in \mathbb{R}^{m \times n} \) 
                is a randomly initialized weight matrix, 
                \( \mathbf{R} \in \mathbb{R}^{m \times m} \) 
                and 
                \( \mathbf{P} \in \mathbb{R}^{n \times n} \) 
                are two orthogonal matrices. Instead of optimizing weight matrices directly, POET keeps the randomly initialized weight matrix 
                \( \mathbf{W}_0 \) 
                unchanged during training and learns two orthogonal matrices 
                \( \mathbf{R}, \mathbf{P} \) 
                to transform 
                \( \mathbf{W}_0 \).
                This reparameterization preserves the singular values of weights while allowing flexible optimization of the singular vectors.
              </p>
              <div class="content has-text-centered">
                <img src="static/images/sv_comp.png" alt="algebraic reasoning" class="center" style="width: 90%; height: auto;">
                <p> Visualization of the weight update mechanism of POET-BS and POET-FS after 100 steps of update and \(T_m = 1\). </p>
              </div>
              <br>
              <p>
                Our proposed POET has two key properties:
                <ul>
                  <li>
                    <strong>Strong spectrum control:</strong> Because orthogonal transformations do not change the singular values of weight matrices, POET keeps the weight spectrum the same as the randomly initialized weight matrices (empirically validated even with approximations). Through the initialization scheme, POET thus directly controls the singular value distribution of its weight matrices. As a result, and in contrast to standard LLM training, POET matrices avoid undesirable large singular values after training. To further facilitate the POET algorithm, we introduce two new initialization schemes: <em>normalized Gaussian initialization</em> and <em>uniform spectrum initialization</em>, which can ensure the resulting weight matrices have bounded singular values.
                  </li>
                  <li>
                    <strong>Efficient approximation:</strong> While a naive implementation of POET can be computationally expensive, its inherent flexibility opens up opportunities for efficient and scalable training. To address the key challenge of optimizing large orthogonal matrices, we introduce two levels of approximations: <em>stochastic primitive optimization</em>, which factorizes a large orthogonal matrix \( \mathbf{R} \in \mathbb{R}^{m \times m} \) into a product of primitive orthogonal matrices with fewer trainable parameters and uses a merge-then-reinitialize trick for efficiency, and <em>approximate orthogonality via Cayley-Neumann parameterization</em>, which maintains orthogonality with low computational overhead by approximating the Cayley orthogonal parameterization with Neumann series and also benefits from the merge-then-reinitialize trick to prevent error accumulation.
                  </li>
                </ul>
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    </div>
  </section>


<!-- BUILDING SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mmmu">Training with POET</h1>
  </div>
</section>


<section class="section">
<div class="container">
  <!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->
  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Training Algorithm</h2>
          <div class="content has-text-justified">
            <p><strong>Step 1: Initialization.</strong> We initialize the weight matrices using normalized Gaussian: \( \mathbf{W} \leftarrow \mathbf{W}_0 \).</p>
            <p><strong>Step 2: Orthogonal matrix initialization.</strong> For fully stochastic SPO, we randomly sample an index set \( \mathbf{S} \), and parameterize \( \tilde{\mathbf{G}}_{R} \in \mathbb{R}^{b \times b} \) and \( \tilde{\mathbf{G}}_{P} \in \mathbb{R}^{b \times b} \) using CNP. Both matrices are initialized as identity, so \( \mathbf{R} \) and \( \mathbf{P} \) also start as identity matrices. For block-stochastic SPO, we sample a random permutation matrix \( \mathbf{\Psi}_R, \mathbf{\Psi}_P \), and parameterize \( \{ \tilde{\mathbf{G}}_R^{1}, \cdots, \tilde{\mathbf{G}}_R^{\lceil m/b \rceil} \} \) and \( \{ \tilde{\mathbf{G}}_P^{1}, \cdots, \tilde{\mathbf{G}}_P^{\lceil m/b \rceil} \} \) using CNP. Then we initialize them as the identity, so \( \mathbf{R} \) and \( \mathbf{P} \) again start as identity matrices.</p>
            <p><strong>Step 3: Efficient orthogonal parameterization.</strong> For fully stochastic SPO, we have \( \mathbf{R} = \mathbf{I}_m + \mathbf{D}(\mathbf{S})(\tilde{\mathbf{G}}_R - \mathbf{I}_b)\mathbf{D}(\mathbf{S})^\top \) and \( \mathbf{P} = \mathbf{I}_m + \mathbf{D}(\mathbf{S})(\tilde{\mathbf{G}}_P - \mathbf{I}_b)\mathbf{D}(\mathbf{S})^\top \). For block-stochastic SPO, we have \( \mathbf{R} = \mathbf{\Psi}_R^\top \mathrm{Diag}(\tilde{\mathbf{G}}^1_R, \cdots, \tilde{\mathbf{G}}^{\lceil m/b \rceil}_R)\mathbf{\Psi}_R \) and \( \mathbf{P} = \mathbf{\Psi}_P^\top \mathrm{Diag}(\tilde{\mathbf{G}}^1_P, \cdots, \tilde{\mathbf{G}}^{\lceil m/b \rceil}_P)\mathbf{\Psi}_P \).</p>
            <p><strong>Step 4: Inner training loop for updating orthogonal matrices.</strong> The equivalent weight matrix in the forward pass is \( \mathbf{R}\mathbf{W}\mathbf{P} \). Gradients are backpropagated through \( \mathbf{R} \) and \( \mathbf{P} \) to update \( \tilde{\mathbf{G}}_{R}, \tilde{\mathbf{G}}_{P} \) (fully stochastic) or \( \tilde{\mathbf{G}}_{R}^i, \tilde{\mathbf{G}}_{P}^i, \forall i \) (block-stochastic). This inner loop runs for a fixed number of iterations.</p>
            <p><strong>Step 5: Merge-then-reinitialize.</strong> The learned orthogonal matrices \( \mathbf{R} \) and \( \mathbf{P} \) are merged into the weight matrix by \( \mathbf{W} \leftarrow \mathbf{R}\mathbf{W}\mathbf{P} \). If not terminated, return to <strong>Step 2</strong> for reinitialization.</p>
          </div>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Efficient Approximation to Orthogonality</h2>
          <div class="content has-text-justified">
            <p>
              POET is conceptually simple, requiring only the optimization of two orthogonal matrices. However, these matrices are typically large, and naively optimizing them leads to significant computational challenges. We introduce the <strong>Stochastic Primitive Optimization</strong> (SPO). The core idea of SPO is inspired by how QR factorization is performed using Givens rotations and Householder transformations. Both methods construct a large orthogonal matrix \( \mathbf{R} \) by sequentially applying primitive orthogonal transformations (e.g., Givens rotations or Householder reflections), i.e., \( \mathbf{R} = \prod_{i=1}^c \mathbf{G}_i \), where \( \mathbf{G}_i \) denotes the \( i \)-th primitive orthogonal matrix. While each \( \mathbf{G}_i \) is of the same size as \( \mathbf{R} \), it is parameterized by significantly fewer degrees of freedom. Both Givens rotation and Householder reflection use relatively low-capacity parameterizations—for example, each Givens rotation \( \mathbf{G}_i \) involves only a single effective parameter—which limits their efficiency in representing the full orthogonal matrix. SPO follows a similar idea of factorizing the original orthogonal matrix into multiple primitive orthogonal matrices. However, unlike Givens and Householder methods, SPO treats the number of effective parameters in each primitive matrix as a tunable hyperparameter and adopts a stochastic sparsity pattern.
            </p>
            <img src="static/images/block_pattern.png" alt="algebraic reasoning" class="center" style="width: 100%; height: auto;">
            <br>
            <ul>
              <li>
                <strong>Fully stochastic SPO.</strong> The basic idea of fully stochastic SPO is to randomly sample a small submatrix and enforce its orthogonality, allowing it to be easily extended to a full orthogonal matrix by embedding it within an identity matrix—a process similar to Givens or Householder transformations. To represent a large orthogonal matrix \( \mathbf{R} \in \mathbb{R}^{m \times m} \), we start by defining \( c \) index sets \( \mathbf{S}^j = \{ s^j_1, \cdots, s^j_b \} \subseteq \{ 1, \cdots, m \} \) (\( j \in [1, c] \)), where each set has cardinality \( |\mathbf{S}^j| = b \), a hyperparameter controlling the number of effective parameters of a primitive orthogonal matrix. \( \mathbf{S}^j, \forall j \) are randomly sampled from the full indices \( \{ 1, \cdots, m \} \). Let \( \tilde{\mathbf{G}}_j \in \mathbb{R}^{b \times b} \) be a small orthogonal matrix, and \( \mathbf{D}(\mathbf{S}^j) = \{ \mathbf{e}(s^j_1), \cdots, \mathbf{e}(s^j_b) \} \in \mathbb{R}^{m \times b} \) be a selection matrix, where \( \mathbf{e}(k) \) is the standard basis vector with a 1 in the \( k \)-th position and 0 elsewhere. The factorization is given by:
                <br><br>
                <span style="display:block; text-align:center;">
                  \( \mathbf{R} = \prod_{i=1}^c \left( \underbrace{ \mathbf{I}_m + \mathbf{D}(\mathbf{S}^i) \cdot (\tilde{\mathbf{G}}_i - \mathbf{I}_b) \cdot \mathbf{D}(\mathbf{S}^i)^\top }_{ \mathbf{G}_i\text{: The } i\text{-th primitive orthogonal matrix} } \right), \quad \text{s.t.}~ \tilde{\mathbf{G}}_i^\top \tilde{\mathbf{G}}_i = \tilde{\mathbf{G}}_i \tilde{\mathbf{G}}_i^\top = \mathbf{I}_b,~\forall i \)
                </span>
                <br>
                where \( \mathbf{D}(\mathbf{S}^i) \cdot (\mathbf{A}) \cdot \mathbf{D}(\mathbf{S}^i)^\top \) is a projector that replaces the \( b \times b \) sub-block with \( \mathbf{A} \). \( \mathbf{I}_m \) and \( \mathbf{I}_b \) are identity matrices of size \( m \times m \) and \( b \times b \), respectively. To efficiently parameterize small orthogonal matrices \( \tilde{\mathbf{G}}_i \), we can use the CNP introduced in the next section.
              </li>
              <li>
                <strong>Block-stochastic SPO.</strong> While fully stochastic SPO is simple, it may fail to transform all neuron dimensions because the identity matrix leaves part of the space unchanged. To address this, we propose block-stochastic SPO, which first constructs a block-diagonal orthogonal matrix with small blocks for parameter efficiency, and then applies a random permutation to enhance expressiveness by randomizing the sparsity pattern. Block-stochastic SPO transforms all neuron dimensions simultaneously. Formally, we have:
                <br><br>
                <span style="display:block; text-align:center;">
                  \( \mathbf{R} = \prod_{i=1}^c \left( \underbrace{ \mathbf{\Psi}_i^\top \cdot \mathrm{Diag}(\tilde{\mathbf{G}}^1_i, \tilde{\mathbf{G}}^2_i, \cdots, \tilde{\mathbf{G}}^{\lceil m/b \rceil}_i) \cdot \mathbf{\Psi}_i }_{ \mathbf{G}_i\text{: The } i\text{-th primitive orthogonal matrix} } \right), \quad \text{s.t.}~ (\tilde{\mathbf{G}}_i^j)^\top \tilde{\mathbf{G}}_i^j = \tilde{\mathbf{G}}_i^j (\tilde{\mathbf{G}}_i^j)^\top = \mathbf{I}_b,~\forall i, j \)
                </span>
                <br>
                where \( \tilde{\mathbf{G}}^j_i \in \mathbb{R}^{b \times b} \) is the \( j \)-th block of the block diagonal matrix, and \( \mathbf{\Psi}_i, \forall i \) are all random permutation matrices. As long as each diagonal block \( \tilde{\mathbf{G}}^j_i \) is an orthogonal matrix, both \( \mathbf{G}_i \) and \( \mathbf{R} \) are also orthogonal matrices. We also use CNP to efficiently parameterize each orthogonal block \( \tilde{\mathbf{G}}^j_i \).
              </li>
              <li>
                <strong>Cayley-Neumann Parameterization (CNP)</strong>
                <p>
                  The classic Cayley parameterization generates an orthogonal matrix \(\mathbf{R}\) in the form of \(\mathbf{R}=(\mathbf{I}+\mathbf{Q})(\mathbf{I}-\mathbf{Q})^{-1}\) where \(\mathbf{Q}\) is a skew-symmetric matrix satisfying \(\mathbf{Q}=-\mathbf{Q}^\top\). A minor caveat of this parameterization is that it only produces orthogonal matrices with determinant \(1\) (i.e., elements of the special orthogonal group), but empirical results in Orthogonal Finetuning (OFT) indicate that this constraint does not hurt performance. However, the matrix inverse in the original Cayley parameterization introduces numerical instability and computational overhead, limiting its scalability to large orthogonal matrices. To address this, we approximate the matrix inverse using a truncated Neumann series:
                </p>
                \begin{equation}\label{eq:cnp}
                  \mathbf{R}=(\mathbf{I}+\mathbf{Q})(\mathbf{I}-\mathbf{Q})^{-1}=(\mathbf{I}+\mathbf{Q})\cdot\big(\sum_{i=0}^\infty \mathbf{Q}^i \big) \approx (\mathbf{I}+\mathbf{Q})\cdot\big(\mathbf{I}+\sum_{i=1}^k \mathbf{Q}^i \big),
                \end{equation}
                <p>
                  where a larger number of approximation terms \(k\) leads to a smaller approximation error. By avoiding matrix inversion, the training stability of POET is improved; however, this comes with a price--the approximation is valid only when the Neumann series converges in the operator norm. To initialize orthogonal matrices as identity, we set \(\mathbf{Q}\) to a zero matrix in CNP, satisfying the convergence condition initially. As the training progresses, however, updates to \(\mathbf{Q}\) may cause its operator norm to exceed \(1\), violating this condition. Fortunately, our merge-then-reinitialize trick mitigates this issue by periodically resetting \(\mathbf{Q}\) to a zero matrix, ensuring its operator norm remains small.
                </p>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>
  </div>
</section>



<!-- BUILDING SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mmmu">Beyond AdamW: Fewer Parameters, Lower Perplexity</h1>
  </div>
</section>


<section class="section">
<div class="container">
  <!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->
  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">LLM Pretraining using LLaMA Transformer Architecture</h2>
          <div class="content has-text-justified">
            <p>
              We perform the pretraining experiments on the Llama transformers of varying sizes (60M, 130M, 350M, 1.3B) for POET. We use the C4 dataset, a cleaned web crawl corpus from Common Crawl, widely used for LLM pretraining. The training results are summarized below, the validation perplexity and the trainable parameters are reported.
            </p>
            <div class="table-container">
              <table>
                <thead>
                  <tr>
                    <th>Model (# tokens)</th>
                    <th>60M (30B)</th>
                    <th>130M (40B)</th>
                    <th>350M (40B)</th>
                    <th>1.3B (50B)</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>AdamW</td>
                    <td>26.68 (25.30M)</td>
                    <td>20.82 (84.93M)</td>
                    <td>16.78 (302.38M)</td>
                    <td>14.73 (1.21B)</td>
                  </tr>
                  <tr>
                    <td>Galore</td>
                    <td>29.81 (25.30M)</td>
                    <td>22.35 (84.93M)</td>
                    <td>17.99 (302.38M)</td>
                    <td>18.33 (1.21B)</td>
                  </tr>
                  <tr>
                    <td>LoRA<sub>r=64</sub></td>
                    <td>39.70 (4.85M)</td>
                    <td>32.07 (11.21M)</td>
                    <td>25.19 (30.28M)</td>
                    <td>20.55 (59.38M)</td>
                  </tr>
                  <tr style="background-color: #f5f7fa;">
                    <td>POET<sub>BS, b=64</sub></td>
                    <td>29.52 (2.39M)</td>
                    <td>24.52 (5.52M)</td>
                    <td>20.29 (14.90M)</td>
                    <td>18.28 (29.22M)</td>
                  </tr>
                  <tr style="background-color: #f5f7fa;">
                    <td>POET<sub>BS, b=128</sub></td>
                    <td>26.90 (4.81M)</td>
                    <td>21.86 (11.12M)</td>
                    <td>18.05 (30.04M)</td>
                    <td>16.24 (58.91M)</td>
                  </tr>
                  <tr style="background-color: #f5f7fa;">
                    <td>POET<sub>BS, b=256</sub></td>
                    <td><b>25.29</b> (9.66M)</td>
                    <td><b>19.88</b> (22.33M)</td>
                    <td>16.27 (60.32M)</td>
                    <td>14.56 (118.26M)</td>
                  </tr>
                  <tr style="background-color: #f5f7fa;">
                    <td>POET<sub>FS, b=1/8</sub></td>
                    <td>34.06 (0.53M)</td>
                    <td>29.67 (1.78M)</td>
                    <td>24.61 (6.34M)</td>
                    <td>18.46 (25.39M)</td>
                  </tr>
                  <tr style="background-color: #f5f7fa;">
                    <td>POET<sub>FS, b=1/4</sub></td>
                    <td>28.69 (2.13M)</td>
                    <td>23.55 (7.13M)</td>
                    <td>19.42 (25.44M)</td>
                    <td>17.60 (101.66M)</td>
                  </tr>
                  <tr style="background-color: #f5f7fa;">
                    <td>POET<sub>FS, b=1/2</sub></td>
                    <td>25.37 (8.54M)</td>
                    <td>19.94 (28.56M)</td>
                    <td><b>15.95</b> (101.86M)</td>
                    <td><b>13.70</b> (406.88M)</td>
                  </tr>
                </tbody>
              </table>
            </div> 
            <img src="static/images/val_ppl.png" alt="algebraic reasoning" class="center" style="width: 90%; height: auto;">
            <br>
          </div>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Parameter and Memory Complexity</h2>
          <div class="content has-text-justified">
            <p>
              By introducing a hyperparameter \( b \) as the sampling budget, fully stochastic SPO decouples parameter complexity from the size of the weight matrices. With a small \( b \), POET becomes highly parameter-efficient, though at the cost of slower convergence. This offers users a flexible trade-off between efficiency and speed. In contrast, block-stochastic SPO has parameter complexity dependent on the matrix size (i.e., \( m + n \)), making it more scalable than AdamW, which requires \( mn \) trainable parameters. In terms of memory complexity, both POET variants can be much more efficient than AdamW with a suitable sampling budget \( b \). A comparison of parameter and memory complexity is given below:
            </p>
            <div style="text-align: center;">
              <table style="width: auto; border-collapse: collapse; margin: 1em auto;">
                <thead>
                  <tr>
                    <th style="padding: 8px; border-bottom: 2px solid #ddd; text-align: left;"><strong>Method</strong></th>
                    <th style="padding: 8px; border-bottom: 2px solid #ddd; text-align: center;"># <strong>trainable params</strong></th>
                    <th style="padding: 8px; border-bottom: 2px solid #ddd; text-align: center;"><strong>Memory cost</strong></th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td style="padding: 8px;">AdamW</td>
                    <td style="padding: 8px; text-align: center;">\( mn \)</td>
                    <td style="padding: 8px; text-align: center;">\( 3mn \)</td>
                  </tr>
                  <tr>
                    <td style="padding: 8px;">GaLore</td>
                    <td style="padding: 8px; text-align: center;">\( mn \)</td>
                    <td style="padding: 8px; text-align: center;">\( mn + mr + 2nr \)</td>
                  </tr>
                  <tr style="background-color: #f5f7fa;">
                    <td style="padding: 8px;">POET (FS)</td>
                    <td style="padding: 8px; text-align: center;">\( b(b-1) \)</td>
                    <td style="padding: 8px; text-align: center;">\( mn + 3b(b-1) \)</td>
                  </tr>
                  <tr style="background-color: #f5f7fa;">
                    <td style="padding: 8px;">POET (BS)</td>
                    <td style="padding: 8px; text-align: center;">\( \frac{1}{2}(m+n)(b-1) \)</td>
                    <td style="padding: 8px; text-align: center;">\( mn + \frac{3}{2}(m+n)(b-1) \)</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <br>
          </div>
        </div>
      </div>
    </div>
  </section>
  </div>
</section>



<!-- BUILDING SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 id="SIT" class="title is-1 mmmu">Discussions and Intriging Insights</h1>
  </div>
</section>


<section class="section">
  <div class="container">

    <!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->
    <section class="section">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Connection to Generalization Theory</h2>
            <div class="content has-text-justified">
              <p>
                Several previous works generalization results based on bounding the spectral norm of weight matrices. In particular, the spectrally-normalized margin analysis from Bartlett et al. bounds the misclassification error in terms of a margin-based training loss and a complexity term. The complexity term is proportional to 
                \( Q/(\gamma n) \) where \( \gamma \) and \( n \) are margin and sample size and \( Q \)
                bounds the spectral complexity. For an \( L \)-layer ReLU MLP
                and maximal width \( d \), \( Q \) is bounded by
              </p>
              <div style="text-align: center;">
                <p>
                  \( Q = \left( \prod_{i=1}^L \lVert \mathbf{W}_i \rVert \right) \left( \sum_{i=1}^L \frac{(\sqrt{d} \lVert \mathbf{W}_i \rVert_F)^{2/3} }{ \lVert \mathbf{W}_i \rVert^{2/3} } \right)^{3/2} \)
                </p>
              </div>
              <p>
                where \( \lVert \cdot \rVert \)
                and \( \lVert \cdot \rVert_F \) denote spectral and Frobenius norm respectively. Those norms remain invariant when training the network with POET and at initialization they can be bounded with high probability using standard results from random matrix theory.
                The scale at initialization is typically chosen such that \( \mathbf{W} \in \mathbb{R}^{d \times d} \) satisfies \( \lVert \mathbf{W} \rVert = O(1) \) and
                \( \lVert \mathbf{W} \rVert_F = O(\sqrt{d}) \)
                so that \( Q = O_L(d) \). For detailed analysis, please refer to the Appendix of the paper.
              </p>
            </div>
          </div>
        </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Performance under a constant parameter budget</h2>
            <div class="content has-text-justified">
              <p>
                Since POET optimizes two orthogonal matrices \( \mathbf{R}, \mathbf{P} \) simultaneously, a natural question arises: <em>which matrix should receive more parameter budget under a fixed total constraint?</em> To investigate this, we conduct a controlled experiment where different ratios of trainable parameters are allocated to \( \mathbf{R} \) and \( \mathbf{P} \) under a fixed total budget. All other settings (e.g., architecture, data) remain unchanged, with full details provided in the Appendix. We use validation perplexity as the evaluation metric. The total parameter budget matches that of fully stochastic POET with \( b = \frac{1}{h}m \) for \( \mathbf{R} \) and \( b = \frac{1}{h}n \) for \( \mathbf{P} \), where \( h = 8 \), \( 4 \), and \( 3 \) correspond to small, medium, and large budgets, respectively. The results show that POET with a balanced allocation between \( \mathbf{R} \) and \( \mathbf{P} \) yields the best performance.
              </p>
              <div class="content has-text-centered">
                <img src="static/images/budget.png" alt="algebraic reasoning" class="center" style="width: 50%; height: auto;">
                <p> Performance of POET under a constant total parameter budget on \( \mathbf{R} \) and \( \mathbf{P} \). </p>
              </div> 
            </div>
          </div>
        </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Weight Update Evenness of Different POET Variants</h2>
            <div class="content has-text-justified">
              <p>
                To understand the higher parameter efficiency of POET-BS compared to POET-FS, we employ a toy example to visualize their different weight update mechanisms by counting the total number of updates for each element of the weight matrix. The visualization results are given below. Specifically, in this experiment, a 64 x 64 matrix was randomly initialized and trained for 100 steps under various POET-BS and POET-FS configurations. The merge-then-reinitialize trick is performed at each iteration, and the same set of weight elements was effectively updated between two successive merge-then-reinitialize operations. For each weight element, we compute its total number of update in these 100 steps. 
              </p>
              <div class="content has-text-centered">
                <img src="static/images/coverage_plot.png" alt="algebraic reasoning" class="center" style="width: 90%; height: auto;">
                <p> Visualization of the weight update mechanism of POET-BS and POET-FS after 100 steps of update and $\` T_m = 1 \`$. </p>
              </div> 
            </div>
          </div>
        </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Neumann Series Approximation of POET.</h2>
            <div class="content has-text-justified">
              <p>
                CNP approximates the matrix inverse using a Neumann series. As the number of Neumann terms directly influences the approximation quality, understanding its impact on model performance is essential. To this end, we evaluate how varying the number of Neumann terms affects performance, using POET-FS with \( b = 1/2 \) to train LLaMA-130M. Results in the following table show that increasing the number of Neumann terms generally improves validation perplexity. However, this also leads to slower training. Moreover, Using only 1 Neumann term (\( k=1 \)) leads to training divergence, highlighting the critical role of maintaining orthogonality. To balance overhead and performance, we find that using 5 Neumann terms is a good trade-off.
              </p>
              <div class="content has-text-centered">
                <img src="static/images/ortho_error.png" alt="algebraic reasoning" class="center" style="width: 90%; height: auto;">
                <p> Approximation error of orthogonal matrices \( \mathbf{R} \) and \( \mathbf{P} \) of a weight matrix. </p>
              </div> 
              <div style="text-align: center;">
                <table style="width: auto; border-collapse: collapse; margin: 1em auto;">
                  <thead>
                    <tr>
                      <th style="padding: 8px; border-bottom: 2px solid #ddd; text-align: left;"><strong>Scheme</strong></th>
                      <th style="padding: 8px; border-bottom: 2px solid #ddd; text-align: left;"><strong>Perplexity</strong></th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td style="padding: 8px;">\( k=1 \)</td>
                      <td style="padding: 8px;">Not converged</td>
                    </tr>
                    <tr>
                      <td style="padding: 8px;">\( k=2 \)</td>
                      <td style="padding: 8px;">22.56</td>
                    </tr>
                    <tr>
                      <td style="padding: 8px;">\( k=3 \)</td>
                      <td style="padding: 8px;">21.54</td>
                    </tr>
                    <tr>
                      <td style="padding: 8px;">\( k=4 \)</td>
                      <td style="padding: 8px;">20.22</td>
                    </tr>
                    <tr>
                      <td style="padding: 8px;">\( k=5 \)</td>
                      <td style="padding: 8px;"><strong>20.19</strong></td>
                    </tr>
                  </tbody>
                </table>
              </div>
            </div>
          </div>
        </div>

      </div>
    </section>
    </div>
  </section>




<!-- @PAN TODO: bibtex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>
      @article{qiu2024can, 
        title={Can Large Language Models Understand Symbolic Graphics Programs?}, 
        author={Qiu, Zeju and Liu, Weiyang and Feng, Haiwen and Liu, Zhen and Xiao, Tim Z and Collins, Katherine M and Tenenbaum, Joshua B and Weller, Adrian and Black, Michael J and Sch{\"o}lkopf, Bernhard}, 
        journal={arXiv preprint arXiv:2408.08313}, 
        year={2024} 
      }
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">
        <p>
          This website is website adapted from <a href="https://nerfies.github.io/">Nerfies</a>, <a href="https://mathvista.github.io/">MathVista</a> and  <a href="https://sgp-bench.github.io/">SGP-Bench</a>, licensed under a <a rel="license"
                                              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
          Commons Attribution-ShareAlike 4.0 International License</a>.
        </p>
      </div>
    </div>
  </div>
</footer>

<script>
  document.addEventListener('DOMContentLoaded', function () {
      // Initialize tablesort for both tables
      var table1 = new Tablesort(document.getElementById('table1'));
      var table2 = new Tablesort(document.getElementById('table2'));

      // Sort the tables by the 'Overall' column (index 3)
      function sortByOverall(table) {
          var rows = Array.from(table.querySelectorAll('tbody > tr'));
          rows.sort((rowA, rowB) => {
              var cellA = parseFloat(rowA.cells[3].textContent);
              var cellB = parseFloat(rowB.cells[3].textContent);
              return cellB - cellA;
          });
          rows.forEach(row => table.querySelector('tbody').appendChild(row));
      }

      // Sort both tables by the 'Overall' column on page load
      sortByOverall(document.getElementById('table1'));
      sortByOverall(document.getElementById('table2'));
  });

  function changeButtonText() {
      var table1 = document.getElementById('table1');
      var table2 = document.getElementById('table2');
      if (table1.classList.contains('hidden')) {
          table1.classList.remove('hidden');
          table2.classList.add('hidden');
      } else {
          table1.classList.add('hidden');
          table2.classList.remove('hidden');
      }
  }




  function changeButtonText() {
    var button = document.getElementById('toggleButton');
    if (button.innerHTML.includes("SGP-Bench (SVG) Leaderboard")) {
      button.innerHTML = "<b style='font-size: larger;'>SGP-Bench (CAD) Leaderboard</b> (Click to Switch)";
    } else {
      button.innerHTML = "<b style='font-size: larger;'>SGP-Bench (SVG) Leaderboard</b> (Click to Switch)";
    }
  }
  document.addEventListener('DOMContentLoaded', function() {
    var tables = document.querySelectorAll('table');

    tables.forEach(function(table) {
        if (!table) return;

        var initialRows = Array.from(table.rows).slice(1);
        table.addEventListener('click', function(event) {
            var clickedCell = event.target.closest('td, th');
            if (!clickedCell) return;
            var headerRow = clickedCell.parentNode;
            var columnIndex = Array.from(headerRow.cells).indexOf(clickedCell);
            var type = clickedCell.getAttribute('data-type');

            if (headerRow.rowIndex === 0) {
                if (columnIndex === 0) {
                    table.tBodies[0].innerHTML = '';
                    initialRows.forEach(row => table.tBodies[0].appendChild(row.cloneNode(true)));
                }
            }
        });
    });
});

  function toggleTables () {
      var table1 = document.getElementById('table1');
      var table2 = document.getElementById('table2');
      table1.classList.toggle('hidden');
      table2.classList.toggle('hidden');
      
      var desc1 = document.querySelector('p.validation-desc');
      var desc2 = document.querySelector('p.test-desc');
      desc1.classList.toggle('hidden');
      desc2.classList.toggle('hidden');
  }

  document.getElementById('toggleButton').addEventListener('click', toggleTables);

  const canvas = document.getElementById('difficulty_level_chart');
  canvas.style.width = '500px';
  canvas.style.height = '120px';
  const ctx = document.getElementById('difficulty_level_chart').getContext('2d');
  const difficulty_level_chart = new Chart(ctx, {
    type: 'bar',
    data: {
      labels: ['Easy', 'Medium', 'Hard', 'Overall'],
      datasets: [{
        label: 'Adept Fuyu-8B',
        data: [28.9, 27, 26.4, 27.4],
        backgroundColor: 'rgba(196, 123, 160, 0.6)',
        borderColor: 'rgba(196, 123, 160, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(196, 123, 160, 1)'
      },
      {
        label: 'Qwen-VL-7B-Chat',
        data: [39.4, 31.9, 27.6, 32.9],
        backgroundColor: 'rgba(245, 123, 113, 0.6)',
        borderColor: 'rgba(245, 123, 113, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(245, 123, 113, 1)'
      },
      {
        label: 'LLaVA-1.5-13B',
        data: [41.3, 32.7, 26.7, 33.6],
        backgroundColor: 'rgba(255, 208, 80, 0.6)',
        borderColor: 'rgba(255, 208, 80, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 208, 80, 1)'
      },
      {
        label: 'InstructBLIP-T5-XXL',
        data: [40.3, 32.3, 29.4, 33.8],
        backgroundColor: 'rgba(110, 194, 134, 0.6)',
        borderColor: 'rgba(110, 194, 134, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(110, 194, 134, 1)'
      },
      {
        label: 'BLIP-2 FLAN-T5-XXL',
        data: [41, 32.7, 28.5, 34],
        backgroundColor: 'rgba(255, 153, 78, 0.6)',
        borderColor: 'rgba(255, 153, 78, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 153, 78, 1)'
      },
      {
        label: 'Yi-VL-34B',
        data: [51.0, 39.9, 34.0, 41.6],
        backgroundColor: 'rgba(42, 149, 235, 0.6)',
        borderColor: 'rgba(42, 149, 235, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(42, 149, 235, 1)'
      },
      {
        label: 'LLaVA-1.6-34B',
        data: [56.1, 43.4, 34.4, 44.7],
        backgroundColor: 'rgba(183, 156, 220, 0.6)',
        borderColor: 'rgba(183, 156, 220, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(183, 156, 220, 1)'
      },
      {
        label: 'InternVL-Chat-V1.2',
        data: [56.2, 44.8, 37.8, 46.2],
        backgroundColor: 'rgba(143, 169, 209, 0.6)',
        borderColor: 'rgba(143, 169, 209, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(143, 169, 209, 1)'
      },
      {
        label: 'VILA1.5',
        data: [58.1, 45.5, 36.8, 46.9],
        backgroundColor: 'rgba(172, 199, 176, 0.6)',
        borderColor: 'rgba(172, 199, 176, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(172, 199, 176, 1)'
      },
      {
        label: 'GPT-4V(ision) (Playground)',
        data: [76.1, 55.6, 31.2, 55.7],
        backgroundColor: 'rgba(117, 209, 215, 0.6)',
        borderColor: 'rgba(117, 209, 215, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(117, 209, 215, 1)'
      }]
    },
    options: {
    scales: {
      y: {
        beginAtZero: true,
        min: 0,
        max: 100,
        ticks: {
          stepSize: 20,
          font: {
            size: 16
          }
        }
      },
      x: {
        ticks: {
          font: {
            size: 16 
          }
        }
      }
    },
    plugins: {
      legend: {
        labels: {
          font: {
            size: 16 
          }
        }
      },
      tooltip: {
        callbacks: {
          label: function(context) {
            return context.dataset.label + ': ' + context.parsed.y;
          }
        }
      }
    },
      onHover: (event, chartElement) => {
        event.native.target.style.cursor = chartElement[0] ? 'pointer' : 'default';
      }
    }
  });

  const canvas_image = document.getElementById('single_vs_multiple_chart');
  canvas_image.style.width = '500px';
  canvas_image.style.height = '120px';
  const svm = document.getElementById('single_vs_multiple_chart').getContext('2d');
  const single_vs_multiple_chart = new Chart(svm, {
    type: 'bar',
    data: {
      labels: ['InternLM-XComposer2-VL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V(ision) (Playground)'],
      datasets: [{
        label: 'Single Image',
        data: [38.6, 42, 45.1, 46.9, 47, 56.1],
        backgroundColor: 'rgba(42, 149, 235, 0.6)', 
        borderColor: 'rgba(42, 149, 235, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(42, 149, 235, 1)'
      },
      {
        label: 'Multiple Image',
        data: [34.5, 36.6, 40, 38.4, 45.9, 51.7],
        backgroundColor: 'rgba(255, 153, 78, 0.6)', 
        borderColor: 'rgba(255, 153, 78, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 153, 78, 1)'
      },
      {
        label: 'Overall',
        data: [38.2, 41.6, 44.7, 46.2, 46.9, 55.7],
        backgroundColor: 'rgba(110, 194, 134, 0.6)',  
        borderColor: 'rgba(110, 194, 134, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(110, 194, 134, 1)'
      }]
    },
    options: {
    scales: {
      y: {
        beginAtZero: true,
        min: 0,
        max: 80,
        ticks: {
          stepSize: 20,
          font: {
            size: 16
          }
        }
      },
      x: {
        ticks: {
          font: {
            size: 16 
          }
        }
      }
    },
    plugins: {
      legend: {
        labels: {
          font: {
            size: 16 
          }
        }
      },
      tooltip: {
        callbacks: {
          label: function(context) {
            return context.dataset.label + ': ' + context.parsed.y;
          }
        }
      }
    },
      onHover: (event, chartElement) => {
        event.native.target.style.cursor = chartElement[0] ? 'pointer' : 'default';
      }
    }
  });


  document.addEventListener('DOMContentLoaded', function() {
    // Data for the "Diagrams" chart
    const data_Diagrams = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [27.6, 30.1, 31.8, 30.0, 32.0, 38.5, 40.8, 44.6, 42.8, 46.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };

    // "data_Diagrams" chart
    new Chart(document.getElementById('chart_Diagrams'), {
        type: 'bar',
        data: data_Diagrams,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Tables" chart
    const data_Tables  = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [26.6, 29.0, 29.8, 27.8, 27.8, 33.6, 40.2, 37.8, 39.9, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Tables'), {
        type: 'bar',
        data: data_Tables,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_PlotsAndCharts " chart
    const data_PlotsAndCharts   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [24.8, 31.8, 36.2, 30.4, 35.8, 43.6, 44.9, 44.3, 47.6, 55.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PlotsAndCharts'), {
        type: 'bar',
        data: data_PlotsAndCharts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Photographs " chart
    const data_Photographs   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [27.6, 40.5, 41.4, 44.4, 42.0, 51.9, 57.3, 58.4, 60.9, 64.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Photographs'), {
        type: 'bar',
        data: data_Photographs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_ChemicalStructures " chart
    const data_ChemicalStructures   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [25.0, 27.2, 27.1, 26.7, 25.5, 30.4, 32.5, 35.6, 38.7, 50.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ChemicalStructures'), {
        type: 'bar',
        data: data_ChemicalStructures ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Paintings " chart
    const data_Paintings   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [28.7, 57.2, 53.6, 56.3, 52.1, 67.3, 68.9, 73.1, 71.7, 75.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Paintings'), {
        type: 'bar',
        data: data_Paintings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_GeometricShapes " chart
    const data_GeometricShapes   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [21.1, 25.3, 21.4, 25.6, 28.3, 31, 33.9, 35.7, 37.8, 40.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_GeometricShapes'), {
        type: 'bar',
        data: data_GeometricShapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_SheetMusic " chart
    const data_SheetMusic   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [35.2, 33.4, 34.6, 35.8, 34.9, 37.3, 33.1, 39.4, 37.6, 38.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SheetMusic'), {
        type: 'bar',
        data: data_SheetMusic ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MedicalImages " chart
    const data_MedicalImages   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [25.4, 29.8, 31.6, 36.4, 29.8, 47.8, 50.7, 52.6, 51.8, 59.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MedicalImages'), {
        type: 'bar',
        data: data_MedicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_PathologicalImages " chart
    const data_PathologicalImages   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [26.5, 27.7, 31.2, 35.2, 35.6, 50.2, 57.3, 56.1, 52.6, 63.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PathologicalImages'), {
        type: 'bar',
        data: data_PathologicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MicroscopicImages " chart
    const data_MicroscopicImages   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [27.0, 37.6, 29.2, 36.3, 32.7, 49.1, 54.9, 50.4, 56.6, 58.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MicroscopicImages'), {
        type: 'bar',
        data: data_MicroscopicImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MRIsCTScansXrays " chart
    const data_MRIsCTScansXrays   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [21.7, 36.9, 33.3, 39.4, 29.8, 44.9, 51.5, 48, 48.5, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MRIsCTScansXrays'), {
        type: 'bar',
        data: data_MRIsCTScansXrays ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_SketchesAndDrafts " chart
    const data_SketchesAndDrafts   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [37.0, 32.1, 29.9, 38.0, 33.7, 45.7, 45.7, 48.9, 52.7, 55.4],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SketchesAndDrafts'), {
        type: 'bar',
        data: data_SketchesAndDrafts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Maps " chart
    const data_Maps   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [38.2, 36.5, 45.9, 47.6, 43.5, 52.4, 58.2, 58.2, 62.4, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Maps'), {
        type: 'bar',
        data: data_Maps ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_TechnicalBlueprints " chart
    const data_TechnicalBlueprints   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [24.7, 25.9, 28.4, 25.3, 27.8, 30.9, 37.7, 40.1, 36.4, 38.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TechnicalBlueprints'), {
        type: 'bar',
        data: data_TechnicalBlueprints ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_TreesAndGraphs " chart
    const data_TreesAndGraphs   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.1, 28.1, 28.8, 28.8, 34.9, 43.2, 33.6, 37, 41.1, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TreesAndGraphs'), {
        type: 'bar',
        data: data_TreesAndGraphs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MathematicalNotations " chart
    const data_MathematicalNotations   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [15.8, 27.1, 22.6, 21.8, 21.1, 30.8, 33.8, 36.8, 34.6, 45.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MathematicalNotations'), {
        type: 'bar',
        data: data_MathematicalNotations ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_ComicsAndCartoons " chart
    const data_ComicsAndCartoons   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [29.0, 51.9, 49.6, 54.2, 51.1, 64.9, 63.4, 71, 74.8, 68.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ComicsAndCartoons'), {
        type: 'bar',
        data: data_ComicsAndCartoons ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Sculpture " chart
    const data_Sculpture   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.8, 46.2, 49.6, 51.3, 53.0, 65.8, 69.2, 76.9, 71.8, 76.1],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Sculpture'), {
        type: 'bar',
        data: data_Sculpture ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Portraits " chart
    const data_Portraits   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [20.9, 52.7, 46.2, 54.9, 47.3, 62.6, 62.6, 67, 70.3, 70.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Portraits'), {
        type: 'bar',
        data: data_Portraits ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Screenshots " chart
    const data_Screenshots   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [38.6, 35.7, 38.6, 34.3, 47.1, 52.9, 60, 51.4, 57.1, 65.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Screenshots'), {
        type: 'bar',
        data: data_Screenshots ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Other " chart
    const data_Other   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [28.3, 38.3, 50.0, 51.7, 58.3, 60, 61.7, 60, 68.3, 68.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Other'), {
        type: 'bar',
        data: data_Other ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Poster " chart
    const data_Poster   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [38.6, 50.9, 52.6, 61.4, 64.9, 66.7, 68.4, 71.9, 75.4, 80.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Poster'), {
        type: 'bar',
        data: data_Poster ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_IconsAndSymbols " chart
    const data_IconsAndSymbols   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [23.8, 66.7, 57.1, 59.5, 59.5, 73.8, 73.8, 76.2, 81, 78.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_IconsAndSymbols'), {
        type: 'bar',
        data: data_IconsAndSymbols ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_HistoricalTimelines " chart
    const data_HistoricalTimelines   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.0, 36.7, 40.0, 43.3, 43.3, 50, 66.7, 63.3, 63.3, 63.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_HistoricalTimelines'), {
        type: 'bar',
        data: data_HistoricalTimelines ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_3DRenderings " chart
    const data_3DRenderings   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [33.3, 28.6, 57.1, 38.1, 47.6, 42.9, 42.9, 57.1, 42.9, 47.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_3DRenderings'), {
        type: 'bar',
        data: data_3DRenderings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_DNASequences " chart
    const data_DNASequences   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [20.0, 45.0, 25.0, 25.0, 45.0, 45, 30, 30, 30, 55.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_DNASequences'), {
        type: 'bar',
        data: data_DNASequences ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Landscapes " chart
    const data_Landscapes   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [43.8, 43.8, 50.0, 31.2, 62.5, 50, 68.8, 62.5, 68.8, 68.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Landscapes'), {
        type: 'bar',
        data: data_Landscapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_LogosAndBranding " chart
    const data_LogosAndBranding   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [21.4, 57.1, 64.3, 35.7, 50.0, 57.1, 78.6, 78.6, 71.4, 85.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_LogosAndBranding'), {
        type: 'bar',
        data: data_LogosAndBranding ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Advertisements " chart
    const data_Advertisements   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.0, 60.0, 50.0, 60.0, 70.0, 80, 70, 80, 80, 100.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Advertisements'), {
        type: 'bar',
        data: data_Advertisements ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
});

</script>

<style>
  .hidden {
      display: none;
  }
  .sortable:hover {
      cursor: pointer;
  }
  .asc::after {
      content: ' ↑';
  }
  .desc::after {
      content: ' ↓';
  }
  #toggleButton {
    background-color: #ffffff;
    border: 1px solid #dddddd;
    color: #555555;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 14px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 25px; 
    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    transition-duration: 0.4s;
  }

  #toggleButton:hover {
    box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19); /* 鼠标悬停时的阴影效果 */
  }

  table {
    border-collapse: collapse;
    width: 100%;
    margin-top: 5px;
    border: 1px solid #ddd;
    font-size: 14px;
  }

  th, td {
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
      border-bottom: 2px solid #ddd;
  }

  td:hover {background-color: #ffffff;}
</style>

</body>
</html>
